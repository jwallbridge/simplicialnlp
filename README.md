# Simplicial Transformer Architecture   

This is the code repository for a 2- and 3-Simplicial Transformer Architecture.   It includes both an Encoder and Decoder.

It includes :
* `attention2_layer.py` a 2-simplicial attention layer.
* `transformer2_100.py` a Transformer with 2-simplicial Encoder and standard Decoder.


# Referencing

This code was developed for the project [2simplicialtransformer](https://github.com/dmurfet/2simplicialtransformer) by James Clift, Dmitry Doryn, Daniel Murfet and James Wallbridge. If you find this helpful in your work, you can consider citing the following :

```
@article{clift19,    
  author = {James Clift and Dmitry Doryn and Daniel Murfet and James Wallbridge},    
  title = {Logic and the 2-Simplicial Transformer},    
  journal = {preprint arXiv:1909.00668},    
  year = {2019},    
}
```
